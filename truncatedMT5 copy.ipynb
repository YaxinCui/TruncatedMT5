{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncatedModelPath = \"truncatedModel\"\n",
    "\n",
    "# truncatedTokenizer = AutoTokenizer.from_pretrained(truncatedModelPath)\n",
    "\n",
    "fullMT5Name = \"google/mt5-small\"\n",
    "\n",
    "#fullModel = AutoModelForSeq2SeqLM.from_pretrained(fullMT5Name)\n",
    "fullTokenizer = AutoTokenizer.from_pretrained(fullMT5Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullTokenizer = AutoTokenizer.from_pretrained(\"NewSP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='NewSP', vocab_size=10778, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁<extra_id_99>',\n",
       " '▁<extra_id_98>',\n",
       " '▁<extra_id_97>',\n",
       " '▁<extra_id_96>',\n",
       " '▁<extra_id_95>',\n",
       " '▁<extra_id_94>',\n",
       " '▁<extra_id_93>',\n",
       " '▁<extra_id_92>',\n",
       " '▁<extra_id_91>',\n",
       " '▁<extra_id_90>',\n",
       " '▁<extra_id_89>',\n",
       " '▁<extra_id_88>',\n",
       " '▁<extra_id_87>',\n",
       " '▁<extra_id_86>',\n",
       " '▁<extra_id_85>',\n",
       " '▁<extra_id_84>',\n",
       " '▁<extra_id_83>',\n",
       " '▁<extra_id_82>',\n",
       " '▁<extra_id_81>',\n",
       " '▁<extra_id_80>',\n",
       " '▁<extra_id_79>',\n",
       " '▁<extra_id_78>',\n",
       " '▁<extra_id_77>',\n",
       " '▁<extra_id_76>',\n",
       " '▁<extra_id_75>',\n",
       " '▁<extra_id_74>',\n",
       " '▁<extra_id_73>',\n",
       " '▁<extra_id_72>',\n",
       " '▁<extra_id_71>',\n",
       " '▁<extra_id_70>',\n",
       " '▁<extra_id_69>',\n",
       " '▁<extra_id_68>',\n",
       " '▁<extra_id_67>',\n",
       " '▁<extra_id_66>',\n",
       " '▁<extra_id_65>',\n",
       " '▁<extra_id_64>',\n",
       " '▁<extra_id_63>',\n",
       " '▁<extra_id_62>',\n",
       " '▁<extra_id_61>',\n",
       " '▁<extra_id_60>',\n",
       " '▁<extra_id_59>',\n",
       " '▁<extra_id_58>',\n",
       " '▁<extra_id_57>',\n",
       " '▁<extra_id_56>',\n",
       " '▁<extra_id_55>',\n",
       " '▁<extra_id_54>',\n",
       " '▁<extra_id_53>',\n",
       " '▁<extra_id_52>',\n",
       " '▁<extra_id_51>',\n",
       " '▁<extra_id_50>',\n",
       " '▁<extra_id_49>',\n",
       " '▁<extra_id_48>',\n",
       " '▁<extra_id_47>',\n",
       " '▁<extra_id_46>',\n",
       " '▁<extra_id_45>',\n",
       " '▁<extra_id_44>',\n",
       " '▁<extra_id_43>',\n",
       " '▁<extra_id_42>',\n",
       " '▁<extra_id_41>',\n",
       " '▁<extra_id_40>',\n",
       " '▁<extra_id_39>',\n",
       " '▁<extra_id_38>',\n",
       " '▁<extra_id_37>',\n",
       " '▁<extra_id_36>',\n",
       " '▁<extra_id_35>',\n",
       " '▁<extra_id_34>',\n",
       " '▁<extra_id_33>',\n",
       " '▁<extra_id_32>',\n",
       " '▁<extra_id_31>',\n",
       " '▁<extra_id_30>',\n",
       " '▁<extra_id_29>',\n",
       " '▁<extra_id_28>',\n",
       " '▁<extra_id_27>',\n",
       " '▁<extra_id_26>',\n",
       " '▁<extra_id_25>',\n",
       " '▁<extra_id_24>',\n",
       " '▁<extra_id_23>',\n",
       " '▁<extra_id_22>',\n",
       " '▁<extra_id_21>',\n",
       " '▁<extra_id_20>',\n",
       " '▁<extra_id_19>',\n",
       " '▁<extra_id_18>',\n",
       " '▁<extra_id_17>',\n",
       " '▁<extra_id_16>',\n",
       " '▁<extra_id_15>',\n",
       " '▁<extra_id_14>',\n",
       " '▁<extra_id_13>',\n",
       " '▁<extra_id_12>',\n",
       " '▁<extra_id_11>',\n",
       " '▁<extra_id_10>',\n",
       " '▁<extra_id_9>',\n",
       " '▁<extra_id_8>',\n",
       " '▁<extra_id_7>',\n",
       " '▁<extra_id_6>',\n",
       " '▁<extra_id_5>',\n",
       " '▁<extra_id_4>',\n",
       " '▁<extra_id_3>',\n",
       " '▁<extra_id_2>',\n",
       " '▁<extra_id_1>',\n",
       " '▁<extra_id_0>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullTokenizer.convert_ids_to_tokens([i for i in range(250000, 250100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepTokens = truncatedTokenizer.convert_ids_to_tokens([i for i in range(259, truncatedTokenizer.vocab_size-100)])\n",
    "keepIdInFull = [i for i in range(259)] + fullTokenizer.convert_tokens_to_ids(keepTokens) + [i for i in range(fullTokenizer.vocab_size-100, fullTokenizer.vocab_size)]\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "truncatedModel = deepcopy(fullModel)\n",
    "truncatedModel.config.vocab_size=len(keepIdInFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "truncatedModel.encoder.embed_tokens = nn.Embedding(len(keepIdInFull), truncatedModel.config.hidden_size)\n",
    "truncatedModel.encoder.embed_tokens.data = fullModel.encoder.embed_tokens.weight[keepIdInFull].detach().numpy()\n",
    "\n",
    "truncatedModel.shared = truncatedModel.encoder.embed_tokens\n",
    "\n",
    "truncatedModel.decoder.embed_tokens = nn.Embedding(len(keepIdInFull), truncatedModel.config.hidden_size)\n",
    "truncatedModel.decoder.embed_tokens.data = fullModel.decoder.embed_tokens.weight[keepIdInFull].detach().numpy()\n",
    "\n",
    "truncatedModel.shared = truncatedModel.decoder.embed_tokens\n",
    "\n",
    "truncatedModel.lm_head = nn.Linear(truncatedModel.config.hidden_size, truncatedModel.config.vocab_size, bias=False)\n",
    "truncatedModel.lm_head.weight.data = fullModel.lm_head.weight.data[keepIdInFull]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(truncatedModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncatedModel.save_pretrained(truncatedModelPath)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4262922743ee1db9ee96e18dc118d647a390b2a8401ca1a6a098b56f8b39a228"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('baidu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
